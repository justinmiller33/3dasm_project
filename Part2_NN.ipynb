{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from f3dasm import ExperimentData\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures # For Polynomial basis functions\n",
    "from sklearn.pipeline import make_pipeline # to link different objects\n",
    "from matplotlib import cm # to change colors of surface plots\n",
    "import matplotlib.pyplot as plt # import plotting tools to create figures\n",
    "\n",
    "# NN Libraries\n",
    "from tensorflow import keras # fast library for ANNs\n",
    "from tensorflow.keras.optimizers import Adam # import the optimizer you want to use to calculate the parameters\n",
    "from keras.models import Sequential # to create a feedforward neural network\n",
    "from keras.layers import Dense # to create a feedforward neural network with dense layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # standardize the dataset with scikit-learn\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, r2_score, mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defining our Artificial Neural Network.\n",
    "def create_ANN(input_dimensions=1, # number of input variables\n",
    "               neurons1=3, # number of neurons in first hidden layer\n",
    "               neurons2=2, # number of neurons in second hidden layer\n",
    "               activation='relu', # activation function\n",
    "               optimizer='adam', # optimization algorithm to compute the weights and biases\n",
    "               output_dimensions=1,\n",
    "               output_activation='linear'): # number of output variables\n",
    "    # create model\n",
    "    model = Sequential() # Feedforward architecture\n",
    "    model.add(Dense(neurons1, input_dim=input_dimensions, activation=activation)) # first hidden layer\n",
    "    model.add(Dense(neurons2, activation=activation)) # second hidden layer\n",
    "    model.add(Dense(output_dimensions, activation=output_activation)) # output layer using Linear activation function because\n",
    "                                                             # we are doing regression (we could also ommit the\n",
    "                                                             # activation='linear' command because keras\n",
    "                                                             # would pick the right activation function\n",
    "                                                             # when we ask for the correct loss below)\n",
    "    model.compile(loss='mse', # our NLL (loss or error function)\n",
    "                  optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 15:20:55,319 - f3dasm - INFO - Imported f3dasm (version: 1.4.3)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "domain_3 = pd.read_pickle(\"data/supercompressible_3d_domain.pkl\")\n",
    "input_3 = pd.read_csv(\"data/supercompressible_3d_input.csv\", index_col=0)\n",
    "jobs_3 = pd.read_pickle(\"data/supercompressible_3d_jobs.pkl\")\n",
    "output_3 = pd.read_csv(\"data/supercompressible_3d_output.csv\", index_col=0)\n",
    "\n",
    "domain_7 = pd.read_pickle(\"data/supercompressible_7d_domain.pkl\")\n",
    "input_7 = pd.read_csv(\"data/supercompressible_7d_input.csv\", index_col=0)\n",
    "jobs_7 = pd.read_pickle(\"data/supercompressible_7d_jobs.pkl\")\n",
    "output_7 = pd.read_csv(\"data/supercompressible_7d_output.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating scaled data for classification (3d)\n",
    "testset_ratio = 0.25\n",
    "SEED = 123\n",
    "DIM = 3  # Adjust to run for binary classification instead of 3 class (combines coilable)\n",
    "INPUT_DIM = 3  # Adjust to run for the 3 or 7 variable dataset\n",
    "\n",
    "# Deciding on input dataset\n",
    "if INPUT_DIM == 3:\n",
    "    output = output_3\n",
    "else:\n",
    "    output = output_7\n",
    "\n",
    "# Adjusting Output Dim Classes (if necessary)\n",
    "if DIM == 2:\n",
    "    output_3.coilable = output_3.coilable.astype(bool).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_3, output_3[\"coilable\"].values, test_size=testset_ratio, random_state=SEED)\n",
    "\n",
    "# Class-dimensional y train and test\n",
    "Y_train = np.zeros([len(y_train), 3])\n",
    "for i in range(len(y_train)):\n",
    "    Y_train[i][y_train[i]] = 1\n",
    "    \n",
    "Y_test = np.zeros([len(y_test), 3])\n",
    "for i in range(len(y_test)):\n",
    "    Y_test[i][y_test[i]] = 1\n",
    "\n",
    "# Scaling (standard)\n",
    "scaler = StandardScaler().fit(X_train) \n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Pareameters\n",
    "neurons1=64 # number of neurons for the first hidden layer\n",
    "neurons2=32 # number of neurons for the second hidden layer\n",
    "activation='relu' # choose activation function\n",
    "batch_size = 2500 # considering the entire dataset for updating the weights and biases in each epoch\n",
    "epochs = 500  # number of times we train the neural network with the entire training set\n",
    "optimizer = Adam(learning_rate=0.001) \n",
    "ANN_model = KerasRegressor(model=create_ANN, input_dimensions=len(X_train.columns), neurons1=neurons1, neurons2=neurons2,\n",
    "                           activation=activation, batch_size=batch_size, epochs=epochs,\n",
    "                           optimizer=optimizer, output_dimensions=3, output_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2541 - val_loss: 0.2520\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2499 - val_loss: 0.2479\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2458 - val_loss: 0.2439\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2418 - val_loss: 0.2401\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2379 - val_loss: 0.2364\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2342 - val_loss: 0.2328\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2306 - val_loss: 0.2294\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2272 - val_loss: 0.2260\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2238 - val_loss: 0.2228\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2205 - val_loss: 0.2196\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2174 - val_loss: 0.2166\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2143 - val_loss: 0.2137\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2114 - val_loss: 0.2108\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2085 - val_loss: 0.2080\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2057 - val_loss: 0.2053\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2030 - val_loss: 0.2027\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2004 - val_loss: 0.2001\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1978 - val_loss: 0.1976\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1953 - val_loss: 0.1952\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1928 - val_loss: 0.1928\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1903 - val_loss: 0.1904\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1879 - val_loss: 0.1881\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1856 - val_loss: 0.1859\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1833 - val_loss: 0.1836\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1810 - val_loss: 0.1815\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1787 - val_loss: 0.1793\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1765 - val_loss: 0.1772\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1743 - val_loss: 0.1751\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1721 - val_loss: 0.1731\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1700 - val_loss: 0.1711\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1679 - val_loss: 0.1691\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1658 - val_loss: 0.1672\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1638 - val_loss: 0.1652\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1617 - val_loss: 0.1634\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1597 - val_loss: 0.1616\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1578 - val_loss: 0.1597\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1558 - val_loss: 0.1580\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1539 - val_loss: 0.1562\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1520 - val_loss: 0.1545\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1501 - val_loss: 0.1528\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1483 - val_loss: 0.1512\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1464 - val_loss: 0.1495\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1447 - val_loss: 0.1480\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1429 - val_loss: 0.1464\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1412 - val_loss: 0.1450\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1395 - val_loss: 0.1435\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1379 - val_loss: 0.1421\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1363 - val_loss: 0.1407\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1347 - val_loss: 0.1394\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1332 - val_loss: 0.1382\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1317 - val_loss: 0.1369\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1303 - val_loss: 0.1358\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1289 - val_loss: 0.1346\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1275 - val_loss: 0.1335\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1262 - val_loss: 0.1324\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1249 - val_loss: 0.1314\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1237 - val_loss: 0.1305\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1225 - val_loss: 0.1295\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1214 - val_loss: 0.1286\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1202 - val_loss: 0.1278\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1192 - val_loss: 0.1269\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1181 - val_loss: 0.1262\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1171 - val_loss: 0.1254\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1161 - val_loss: 0.1247\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.1152 - val_loss: 0.1240\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1142 - val_loss: 0.1233\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1134 - val_loss: 0.1227\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1125 - val_loss: 0.1221\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1117 - val_loss: 0.1215\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1108 - val_loss: 0.1209\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1101 - val_loss: 0.1204\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1093 - val_loss: 0.1198\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1086 - val_loss: 0.1193\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1079 - val_loss: 0.1188\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1072 - val_loss: 0.1184\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1065 - val_loss: 0.1179\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1059 - val_loss: 0.1175\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1053 - val_loss: 0.1171\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1047 - val_loss: 0.1167\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1041 - val_loss: 0.1163\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1035 - val_loss: 0.1159\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1030 - val_loss: 0.1155\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1024 - val_loss: 0.1152\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1019 - val_loss: 0.1148\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1014 - val_loss: 0.1145\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1009 - val_loss: 0.1142\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1005 - val_loss: 0.1138\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1000 - val_loss: 0.1135\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0995 - val_loss: 0.1132\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0991 - val_loss: 0.1130\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0987 - val_loss: 0.1127\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0983 - val_loss: 0.1124\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0979 - val_loss: 0.1121\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0975 - val_loss: 0.1119\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0971 - val_loss: 0.1116\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0967 - val_loss: 0.1114\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0964 - val_loss: 0.1111\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0960 - val_loss: 0.1109\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0957 - val_loss: 0.1107\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0954 - val_loss: 0.1104\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0950 - val_loss: 0.1102\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0947 - val_loss: 0.1100\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0944 - val_loss: 0.1098\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0941 - val_loss: 0.1096\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0938 - val_loss: 0.1094\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0935 - val_loss: 0.1092\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0932 - val_loss: 0.1090\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0929 - val_loss: 0.1088\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0926 - val_loss: 0.1086\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0924 - val_loss: 0.1084\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0921 - val_loss: 0.1082\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0918 - val_loss: 0.1080\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0916 - val_loss: 0.1079\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0913 - val_loss: 0.1077\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0911 - val_loss: 0.1075\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0909 - val_loss: 0.1074\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0906 - val_loss: 0.1072\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0904 - val_loss: 0.1070\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0902 - val_loss: 0.1069\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0899 - val_loss: 0.1067\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0897 - val_loss: 0.1066\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0895 - val_loss: 0.1064\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0893 - val_loss: 0.1063\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0891 - val_loss: 0.1061\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0889 - val_loss: 0.1060\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0886 - val_loss: 0.1058\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0884 - val_loss: 0.1057\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0882 - val_loss: 0.1056\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0881 - val_loss: 0.1054\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0879 - val_loss: 0.1053\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0877 - val_loss: 0.1051\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0875 - val_loss: 0.1050\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0873 - val_loss: 0.1049\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0871 - val_loss: 0.1047\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0869 - val_loss: 0.1046\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0867 - val_loss: 0.1045\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0866 - val_loss: 0.1043\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0864 - val_loss: 0.1042\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0862 - val_loss: 0.1040\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0860 - val_loss: 0.1039\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0859 - val_loss: 0.1038\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0857 - val_loss: 0.1036\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0855 - val_loss: 0.1035\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0854 - val_loss: 0.1034\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0852 - val_loss: 0.1032\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0850 - val_loss: 0.1031\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0848 - val_loss: 0.1030\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0847 - val_loss: 0.1028\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0845 - val_loss: 0.1027\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0844 - val_loss: 0.1026\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0842 - val_loss: 0.1024\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0840 - val_loss: 0.1023\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0839 - val_loss: 0.1022\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0837 - val_loss: 0.1021\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0835 - val_loss: 0.1019\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0834 - val_loss: 0.1018\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0832 - val_loss: 0.1017\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0830 - val_loss: 0.1015\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0829 - val_loss: 0.1014\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0827 - val_loss: 0.1013\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0826 - val_loss: 0.1012\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0824 - val_loss: 0.1010\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0822 - val_loss: 0.1009\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0821 - val_loss: 0.1008\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0819 - val_loss: 0.1006\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0818 - val_loss: 0.1005\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0816 - val_loss: 0.1004\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0814 - val_loss: 0.1003\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0813 - val_loss: 0.1002\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0811 - val_loss: 0.1000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0810 - val_loss: 0.0999\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0808 - val_loss: 0.0998\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0807 - val_loss: 0.0997\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0805 - val_loss: 0.0996\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0803 - val_loss: 0.0994\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0802 - val_loss: 0.0993\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0800 - val_loss: 0.0992\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0799 - val_loss: 0.0991\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0797 - val_loss: 0.0990\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0796 - val_loss: 0.0988\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0794 - val_loss: 0.0987\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0792 - val_loss: 0.0986\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0791 - val_loss: 0.0985\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0789 - val_loss: 0.0984\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0788 - val_loss: 0.0982\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0786 - val_loss: 0.0981\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0785 - val_loss: 0.0980\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0783 - val_loss: 0.0979\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0781 - val_loss: 0.0978\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0780 - val_loss: 0.0976\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0778 - val_loss: 0.0975\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0777 - val_loss: 0.0974\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0775 - val_loss: 0.0973\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0773 - val_loss: 0.0971\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0772 - val_loss: 0.0970\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0770 - val_loss: 0.0969\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0769 - val_loss: 0.0968\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0767 - val_loss: 0.0966\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0766 - val_loss: 0.0965\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0764 - val_loss: 0.0964\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0763 - val_loss: 0.0962\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0761 - val_loss: 0.0961\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0760 - val_loss: 0.0959\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0758 - val_loss: 0.0958\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0757 - val_loss: 0.0956\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0755 - val_loss: 0.0955\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0754 - val_loss: 0.0953\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0752 - val_loss: 0.0952\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0751 - val_loss: 0.0950\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0749 - val_loss: 0.0948\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0748 - val_loss: 0.0947\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0746 - val_loss: 0.0945\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0745 - val_loss: 0.0944\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0743 - val_loss: 0.0942\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0742 - val_loss: 0.0940\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0741 - val_loss: 0.0939\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0739 - val_loss: 0.0937\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0738 - val_loss: 0.0936\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0736 - val_loss: 0.0934\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0735 - val_loss: 0.0933\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0733 - val_loss: 0.0931\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0732 - val_loss: 0.0930\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0731 - val_loss: 0.0928\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0729 - val_loss: 0.0927\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0728 - val_loss: 0.0925\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0726 - val_loss: 0.0924\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0725 - val_loss: 0.0922\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.0723 - val_loss: 0.0921\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0722 - val_loss: 0.0919\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0721 - val_loss: 0.0918\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0719 - val_loss: 0.0916\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0718 - val_loss: 0.0915\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0716 - val_loss: 0.0913\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0715 - val_loss: 0.0912\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0713 - val_loss: 0.0910\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0712 - val_loss: 0.0909\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0711 - val_loss: 0.0908\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0709 - val_loss: 0.0906\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0708 - val_loss: 0.0905\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0707 - val_loss: 0.0904\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0705 - val_loss: 0.0903\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0704 - val_loss: 0.0901\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0703 - val_loss: 0.0900\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0701 - val_loss: 0.0899\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0700 - val_loss: 0.0898\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0699 - val_loss: 0.0897\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0698 - val_loss: 0.0896\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0696 - val_loss: 0.0895\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0695 - val_loss: 0.0894\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0694 - val_loss: 0.0893\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0693 - val_loss: 0.0892\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0692 - val_loss: 0.0891\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0690 - val_loss: 0.0890\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0689 - val_loss: 0.0888\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0688 - val_loss: 0.0887\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0687 - val_loss: 0.0886\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0686 - val_loss: 0.0886\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0685 - val_loss: 0.0885\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0684 - val_loss: 0.0884\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0682 - val_loss: 0.0883\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0681 - val_loss: 0.0882\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0680 - val_loss: 0.0881\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0679 - val_loss: 0.0880\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0678 - val_loss: 0.0879\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0677 - val_loss: 0.0878\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0676 - val_loss: 0.0877\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0675 - val_loss: 0.0876\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0674 - val_loss: 0.0875\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0673 - val_loss: 0.0874\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0672 - val_loss: 0.0874\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0671 - val_loss: 0.0873\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0670 - val_loss: 0.0872\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0669 - val_loss: 0.0871\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0668 - val_loss: 0.0871\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0667 - val_loss: 0.0870\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0666 - val_loss: 0.0869\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0665 - val_loss: 0.0869\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0664 - val_loss: 0.0868\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0664 - val_loss: 0.0867\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0663 - val_loss: 0.0867\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0662 - val_loss: 0.0866\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0661 - val_loss: 0.0866\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0660 - val_loss: 0.0865\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0659 - val_loss: 0.0865\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0658 - val_loss: 0.0864\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0657 - val_loss: 0.0864\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0657 - val_loss: 0.0863\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0656 - val_loss: 0.0863\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0655 - val_loss: 0.0862\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0654 - val_loss: 0.0862\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0653 - val_loss: 0.0862\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0652 - val_loss: 0.0861\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0652 - val_loss: 0.0861\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0651 - val_loss: 0.0860\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0650 - val_loss: 0.0860\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0649 - val_loss: 0.0859\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0648 - val_loss: 0.0859\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0648 - val_loss: 0.0858\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0647 - val_loss: 0.0858\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0646 - val_loss: 0.0857\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0645 - val_loss: 0.0857\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0645 - val_loss: 0.0857\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0644 - val_loss: 0.0856\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0643 - val_loss: 0.0856\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0642 - val_loss: 0.0855\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0642 - val_loss: 0.0855\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0641 - val_loss: 0.0854\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0640 - val_loss: 0.0854\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0639 - val_loss: 0.0854\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0639 - val_loss: 0.0853\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0638 - val_loss: 0.0853\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0637 - val_loss: 0.0852\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0637 - val_loss: 0.0852\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0636 - val_loss: 0.0851\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0635 - val_loss: 0.0851\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0634 - val_loss: 0.0850\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0634 - val_loss: 0.0850\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0633 - val_loss: 0.0850\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0632 - val_loss: 0.0849\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0632 - val_loss: 0.0849\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0631 - val_loss: 0.0848\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0630 - val_loss: 0.0848\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0630 - val_loss: 0.0848\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0629 - val_loss: 0.0847\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0629 - val_loss: 0.0847\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0628 - val_loss: 0.0847\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0627 - val_loss: 0.0846\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0627 - val_loss: 0.0846\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0626 - val_loss: 0.0846\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0626 - val_loss: 0.0845\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0625 - val_loss: 0.0845\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0624 - val_loss: 0.0845\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0624 - val_loss: 0.0844\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0623 - val_loss: 0.0844\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0623 - val_loss: 0.0844\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0622 - val_loss: 0.0843\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0621 - val_loss: 0.0843\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0621 - val_loss: 0.0843\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0620 - val_loss: 0.0842\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0620 - val_loss: 0.0842\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0619 - val_loss: 0.0842\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0619 - val_loss: 0.0842\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0618 - val_loss: 0.0841\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0618 - val_loss: 0.0841\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0617 - val_loss: 0.0841\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0616 - val_loss: 0.0841\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0616 - val_loss: 0.0840\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0615 - val_loss: 0.0840\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0615 - val_loss: 0.0840\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0614 - val_loss: 0.0840\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0614 - val_loss: 0.0839\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0613 - val_loss: 0.0839\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0613 - val_loss: 0.0839\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0612 - val_loss: 0.0839\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0612 - val_loss: 0.0838\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0611 - val_loss: 0.0838\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0611 - val_loss: 0.0838\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0610 - val_loss: 0.0837\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0610 - val_loss: 0.0837\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0609 - val_loss: 0.0837\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0609 - val_loss: 0.0837\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0608 - val_loss: 0.0836\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0608 - val_loss: 0.0836\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0607 - val_loss: 0.0836\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0607 - val_loss: 0.0836\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0606 - val_loss: 0.0835\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0606 - val_loss: 0.0835\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0605 - val_loss: 0.0835\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.0605 - val_loss: 0.0834\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0605 - val_loss: 0.0834\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0604 - val_loss: 0.0834\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0604 - val_loss: 0.0833\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0603 - val_loss: 0.0833\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0603 - val_loss: 0.0833\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0602 - val_loss: 0.0832\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0602 - val_loss: 0.0832\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0601 - val_loss: 0.0832\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0601 - val_loss: 0.0831\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0601 - val_loss: 0.0831\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0600 - val_loss: 0.0831\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0600 - val_loss: 0.0831\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0599 - val_loss: 0.0831\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0599 - val_loss: 0.0830\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0598 - val_loss: 0.0830\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0598 - val_loss: 0.0830\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0597 - val_loss: 0.0829\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0597 - val_loss: 0.0829\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0597 - val_loss: 0.0829\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0596 - val_loss: 0.0828\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0596 - val_loss: 0.0828\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0595 - val_loss: 0.0828\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0595 - val_loss: 0.0827\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0594 - val_loss: 0.0827\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0594 - val_loss: 0.0827\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0593 - val_loss: 0.0826\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0593 - val_loss: 0.0826\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0593 - val_loss: 0.0826\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0592 - val_loss: 0.0826\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0592 - val_loss: 0.0825\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0591 - val_loss: 0.0825\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0591 - val_loss: 0.0825\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0591 - val_loss: 0.0825\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0590 - val_loss: 0.0824\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0590 - val_loss: 0.0824\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0589 - val_loss: 0.0824\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0589 - val_loss: 0.0824\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0589 - val_loss: 0.0823\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0588 - val_loss: 0.0823\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0588 - val_loss: 0.0823\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0587 - val_loss: 0.0823\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0587 - val_loss: 0.0822\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0587 - val_loss: 0.0822\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0586 - val_loss: 0.0822\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0586 - val_loss: 0.0822\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0586 - val_loss: 0.0821\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0585 - val_loss: 0.0821\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0585 - val_loss: 0.0821\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0585 - val_loss: 0.0821\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0584 - val_loss: 0.0821\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0584 - val_loss: 0.0821\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0583 - val_loss: 0.0820\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0583 - val_loss: 0.0820\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0583 - val_loss: 0.0820\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0582 - val_loss: 0.0820\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0582 - val_loss: 0.0820\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0582 - val_loss: 0.0820\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0581 - val_loss: 0.0820\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0581 - val_loss: 0.0820\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0581 - val_loss: 0.0820\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0580 - val_loss: 0.0819\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0580 - val_loss: 0.0819\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0580 - val_loss: 0.0819\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0579 - val_loss: 0.0819\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0579 - val_loss: 0.0819\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0579 - val_loss: 0.0818\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0578 - val_loss: 0.0818\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0578 - val_loss: 0.0818\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0578 - val_loss: 0.0818\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0577 - val_loss: 0.0818\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0577 - val_loss: 0.0817\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0577 - val_loss: 0.0817\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0576 - val_loss: 0.0817\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0576 - val_loss: 0.0817\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0576 - val_loss: 0.0816\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0575 - val_loss: 0.0816\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0575 - val_loss: 0.0816\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0575 - val_loss: 0.0816\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0574 - val_loss: 0.0816\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0574 - val_loss: 0.0815\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0574 - val_loss: 0.0815\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0573 - val_loss: 0.0815\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.0573 - val_loss: 0.0815\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0572 - val_loss: 0.0814\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0572 - val_loss: 0.0813\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0572 - val_loss: 0.0813\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0571 - val_loss: 0.0813\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0571 - val_loss: 0.0812\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0571 - val_loss: 0.0812\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0570 - val_loss: 0.0812\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0570 - val_loss: 0.0812\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0570 - val_loss: 0.0812\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0569 - val_loss: 0.0812\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0569 - val_loss: 0.0811\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0569 - val_loss: 0.0811\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0568 - val_loss: 0.0811\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0568 - val_loss: 0.0810\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0568 - val_loss: 0.0810\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0567 - val_loss: 0.0810\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0567 - val_loss: 0.0810\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0567 - val_loss: 0.0809\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0566 - val_loss: 0.0809\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0566 - val_loss: 0.0809\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0566 - val_loss: 0.0808\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0565 - val_loss: 0.0808\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0565 - val_loss: 0.0808\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0564 - val_loss: 0.0807\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0564 - val_loss: 0.0807\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0564 - val_loss: 0.0807\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0563 - val_loss: 0.0806\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0563 - val_loss: 0.0806\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0563 - val_loss: 0.0806\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0562 - val_loss: 0.0806\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0562 - val_loss: 0.0805\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0562 - val_loss: 0.0805\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0561 - val_loss: 0.0805\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0561 - val_loss: 0.0805\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0561 - val_loss: 0.0804\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0560 - val_loss: 0.0804\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0560 - val_loss: 0.0804\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0560 - val_loss: 0.0803\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0559 - val_loss: 0.0803\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0559 - val_loss: 0.0803\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0559 - val_loss: 0.0803\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0558 - val_loss: 0.0802\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0558 - val_loss: 0.0802\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0558 - val_loss: 0.0802\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0557 - val_loss: 0.0802\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0557 - val_loss: 0.0801\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0557 - val_loss: 0.0801\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0556 - val_loss: 0.0801\n"
     ]
    }
   ],
   "source": [
    "# Running model\n",
    "history = ANN_model.fit(X_train_scaled, Y_train, validation_data=(X_test_scaled, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Predicions for y\n",
    "y_pred = history.model_.predict(X_test_scaled) # predict all data points with ANN\n",
    "yp = []\n",
    "for yps in y_pred:\n",
    "    yp.append(np.argmax(yps))\n",
    "    \n",
    "yp = np.array(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70   6   2]\n",
      " [  3  32  18]\n",
      " [  5  12 102]]\n",
      "0.816\n",
      "[0.8974359  0.64       0.83606557]\n",
      "[0.8974359  0.60377358 0.85714286]\n",
      "[0.8974359  0.62135922 0.84647303]\n"
     ]
    }
   ],
   "source": [
    "# Generating matrix and accuracy metrics\n",
    "con_matrix = confusion_matrix(y_test,yp)\n",
    "ac = accuracy_score(y_test, yp)\n",
    "pr = precision_score(y_test, yp, average=None)\n",
    "rc = recall_score(y_test, yp, average=None)\n",
    "f1 = f1_score(y_test, yp, average=None)\n",
    "\n",
    "print(con_matrix)\n",
    "print(ac)\n",
    "print(pr)\n",
    "print(rc)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 35ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ANN Categorical with ratio_top_diameter')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Classification NN Decision Boundary on chosen ratio_top_diameter point (index=249)\n",
    "if INPUT_DIM != 3:\n",
    "    print(\"Warning: Can only generate this plot on the 3d dataset\")\n",
    "    raise Exception(\"Input dim must be three for this plot to work\")\n",
    "\n",
    "# Plot Inputs\n",
    "plt_title = \"ANN Categorical with ratio_top_diameter\"\n",
    "n_classes = DIM\n",
    "plot_colors = 'ryb' # defining the colors for each category (yellow is ignored if n_classes == 2)\n",
    "\n",
    "# Generating grid to plot upon\n",
    "RES = 50\n",
    "X1_data_space = np.linspace(-2, 2, RES)\n",
    "X2_data_space = np.linspace(-2, 2, RES)\n",
    "X3 = X_train_scaled[249][2]\n",
    "xv, yv = np.meshgrid(X1_data_space, X2_data_space)\n",
    "\n",
    "# Filling predictions\n",
    "Z = np.zeros([RES, RES])\n",
    "for j in range(RES):\n",
    "    inp_col = [[X1_data_space[i], X2_data_space[j], X3] for i in range(RES)]\n",
    "    Z[:, j] = np.argmax(history.model_.predict(inp_col), axis=1)\n",
    "    \n",
    "# Plotting\n",
    "fig2, ax2 = plt.subplots(tight_layout=True)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "ax2.contourf(xv, yv, Z, cmap=cm.RdYlBu, alpha=0.8)\n",
    "\n",
    "# Labels and legend\n",
    "ax2.set_ylabel('ratio_d', fontsize=20)\n",
    "ax2.set_xlabel('ratio_pitch', fontsize=20)\n",
    "plt.plot([], [], \".\", color=\"C3\", label=\"Not Coilable\")\n",
    "if n_classes == 2:\n",
    "    plt.plot([], [], \".\", color=\"C0\", label=\"Coilable\")\n",
    "if n_classes == 3:\n",
    "    plt.plot([], [], \".\", color=\"C0\", label=\"Reversibly Coilable\")\n",
    "    plt.plot([], [], \".\", color=\"y\", label=\"Irreversibly Coilable\")\n",
    "    \n",
    "ax2.legend(loc='lower right', borderpad=0, handletextpad=0, fontsize=15)\n",
    "ax2.set_title(plt_title, fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression (Flexible to 3D & 7D Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical works. Let's try regression\n",
    "testset_ratio = 0.25\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DS = 3  # Option to switch input variable here as well\n",
    "if DS == 3:\n",
    "    ip = input_3\n",
    "    op = output_3\n",
    "else:\n",
    "    ip = input_7\n",
    "    op = output_7\n",
    "\n",
    "# Sticking to general strategy of dropping any input data with \n",
    "# Note that this will result in different scalar than before\n",
    "clean_idx = op.dropna().index\n",
    "X_train, X_test, y_train, y_test = train_test_split(ip.iloc[clean_idx], op.iloc[clean_idx][[\"sigma_crit\", \"energy\"]].values, test_size=testset_ratio, random_state=SEED)\n",
    "\n",
    "# Generating X & Y Scaled Data\n",
    "scaler = StandardScaler().fit(X_train) \n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler().fit(y_train)\n",
    "y_train_scaled=scaler_y.transform(y_train)\n",
    "y_test_scaled=scaler_y.transform(y_test)\n",
    "\n",
    "# Generating model\n",
    "neurons1 = 64 # number of neurons for the first hidden layer\n",
    "neurons2 = 32 # number of neurons for the second hidden layer\n",
    "activation = 'relu' # choose activation function\n",
    "batch_size = 200 # considering the entire dataset for updating the weights and biases in each epoch\n",
    "epochs = 1000 # number of times we train the neural network with the entire training set\n",
    "optimizer = Adam(learning_rate=0.001) # specifying the learning rate value for the optimizer (PLAY WITH THIS!)\n",
    "ANN_model = KerasRegressor(model=create_ANN, input_dimensions=len(X_train.columns), neurons1=neurons1, neurons2=neurons2,\n",
    "                           activation=activation, batch_size=batch_size, epochs=epochs,\n",
    "                           optimizer=optimizer, output_dimensions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 2s 516ms/step - loss: 1.0494 - val_loss: 0.9050\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.9862 - val_loss: 0.8483\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9310 - val_loss: 0.7960\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.8770 - val_loss: 0.7475\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.8279 - val_loss: 0.7027\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.7810 - val_loss: 0.6610\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.7392 - val_loss: 0.6214\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6972 - val_loss: 0.5836\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6584 - val_loss: 0.5476\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6213 - val_loss: 0.5132\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.5839 - val_loss: 0.4803\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5486 - val_loss: 0.4492\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.5171 - val_loss: 0.4196\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4865 - val_loss: 0.3919\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4550 - val_loss: 0.3661\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.4293 - val_loss: 0.3419\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.4025 - val_loss: 0.3194\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.3790 - val_loss: 0.2983\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3558 - val_loss: 0.2786\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3316 - val_loss: 0.2606\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.3123 - val_loss: 0.2439\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.2946 - val_loss: 0.2284\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.2765 - val_loss: 0.2141\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2600 - val_loss: 0.2009\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2457 - val_loss: 0.1886\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.2298 - val_loss: 0.1776\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2181 - val_loss: 0.1672\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2064 - val_loss: 0.1576\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1936 - val_loss: 0.1486\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1828 - val_loss: 0.1402\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1722 - val_loss: 0.1325\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.1636 - val_loss: 0.1254\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.1550 - val_loss: 0.1184\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.1467 - val_loss: 0.1120\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.1392 - val_loss: 0.1059\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1319 - val_loss: 0.1002\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.1253 - val_loss: 0.0949\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.1198 - val_loss: 0.0898\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1139 - val_loss: 0.0850\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.1081 - val_loss: 0.0805\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1030 - val_loss: 0.0763\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0984 - val_loss: 0.0723\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0933 - val_loss: 0.0687\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0892 - val_loss: 0.0654\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0856 - val_loss: 0.0623\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0815 - val_loss: 0.0595\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0781 - val_loss: 0.0569\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0747 - val_loss: 0.0544\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0716 - val_loss: 0.0521\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0688 - val_loss: 0.0499\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.0657 - val_loss: 0.0478\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0631 - val_loss: 0.0458\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0605 - val_loss: 0.0440\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0582 - val_loss: 0.0422\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0560 - val_loss: 0.0406\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0539 - val_loss: 0.0391\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0518 - val_loss: 0.0377\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0499 - val_loss: 0.0363\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0482 - val_loss: 0.0350\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0464 - val_loss: 0.0337\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0449 - val_loss: 0.0325\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0433 - val_loss: 0.0314\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0419 - val_loss: 0.0304\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0405 - val_loss: 0.0294\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0392 - val_loss: 0.0285\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0380 - val_loss: 0.0276\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0368 - val_loss: 0.0267\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0357 - val_loss: 0.0259\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0347 - val_loss: 0.0251\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0337 - val_loss: 0.0244\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0327 - val_loss: 0.0237\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0319 - val_loss: 0.0231\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0309 - val_loss: 0.0224\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0302 - val_loss: 0.0218\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0293 - val_loss: 0.0213\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.0285 - val_loss: 0.0207\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0278 - val_loss: 0.0202\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0272 - val_loss: 0.0197\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0264 - val_loss: 0.0192\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0260 - val_loss: 0.0187\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0254 - val_loss: 0.0183\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0248 - val_loss: 0.0179\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0242 - val_loss: 0.0175\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0238 - val_loss: 0.0171\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0232 - val_loss: 0.0167\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0229 - val_loss: 0.0164\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0224 - val_loss: 0.0160\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0220 - val_loss: 0.0157\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0216 - val_loss: 0.0154\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0212 - val_loss: 0.0151\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0208 - val_loss: 0.0149\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0205 - val_loss: 0.0146\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0204 - val_loss: 0.0143\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0199 - val_loss: 0.0141\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0196 - val_loss: 0.0139\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0192 - val_loss: 0.0137\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0191 - val_loss: 0.0135\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0187 - val_loss: 0.0132\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0181 - val_loss: 0.0127\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0178 - val_loss: 0.0125\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0176 - val_loss: 0.0124\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0172 - val_loss: 0.0121\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0168 - val_loss: 0.0118\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0167 - val_loss: 0.0117\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0161 - val_loss: 0.0113\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0159 - val_loss: 0.0112\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0156 - val_loss: 0.0110\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0154 - val_loss: 0.0109\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0125 - val_loss: 0.0090\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0123 - val_loss: 0.0089\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0123 - val_loss: 0.0089\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0118 - val_loss: 0.0086\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0108 - val_loss: 0.0080\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0108 - val_loss: 0.0080\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0105 - val_loss: 0.0078\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0103 - val_loss: 0.0076\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0099 - val_loss: 0.0073\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0098 - val_loss: 0.0073\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0095 - val_loss: 0.0070\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0078 - val_loss: 0.0059\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0073 - val_loss: 0.0055\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0070 - val_loss: 0.0053\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.0069 - val_loss: 0.0051\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 229ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 9.9994e-04 - val_loss: 0.0014\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.9001e-04 - val_loss: 0.0015\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 9.9082e-04 - val_loss: 0.0014\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.8480e-04 - val_loss: 0.0014\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 9.9169e-04 - val_loss: 0.0015\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 9.8222e-04 - val_loss: 0.0014\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 9.8995e-04 - val_loss: 0.0014\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 9.7838e-04 - val_loss: 0.0014\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 9.7397e-04 - val_loss: 0.0014\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 9.8712e-04 - val_loss: 0.0014\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 9.8050e-04 - val_loss: 0.0014\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9.9156e-04 - val_loss: 0.0015\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9.7473e-04 - val_loss: 0.0014\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9.7710e-04 - val_loss: 0.0014\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 9.6558e-04 - val_loss: 0.0015\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 9.6214e-04 - val_loss: 0.0014\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 9.7546e-04 - val_loss: 0.0014\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 9.6276e-04 - val_loss: 0.0015\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 9.6446e-04 - val_loss: 0.0014\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 9.5497e-04 - val_loss: 0.0014\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.7223e-04 - val_loss: 0.0014\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9.6418e-04 - val_loss: 0.0015\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 9.5434e-04 - val_loss: 0.0014\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 9.6943e-04 - val_loss: 0.0014\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 9.4212e-04 - val_loss: 0.0015\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 9.6982e-04 - val_loss: 0.0015\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.6248e-04 - val_loss: 0.0014\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9.4814e-04 - val_loss: 0.0014\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 9.5261e-04 - val_loss: 0.0015\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9.3117e-04 - val_loss: 0.0014\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 9.3849e-04 - val_loss: 0.0014\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9.2211e-04 - val_loss: 0.0014\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 9.5164e-04 - val_loss: 0.0014\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 9.2114e-04 - val_loss: 0.0014\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.3439e-04 - val_loss: 0.0014\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 9.2712e-04 - val_loss: 0.0015\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 9.5241e-04 - val_loss: 0.0014\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.2344e-04 - val_loss: 0.0014\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9.2087e-04 - val_loss: 0.0014\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.4125e-04 - val_loss: 0.0014\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9.7161e-04 - val_loss: 0.0013\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9.5012e-04 - val_loss: 0.0014\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9.1778e-04 - val_loss: 0.0014\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 9.0851e-04 - val_loss: 0.0014\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 9.0912e-04 - val_loss: 0.0014\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9.3425e-04 - val_loss: 0.0014\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 8.9848e-04 - val_loss: 0.0014\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 9.1284e-04 - val_loss: 0.0014\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 9.0049e-04 - val_loss: 0.0014\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 8.9891e-04 - val_loss: 0.0014\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 9.0388e-04 - val_loss: 0.0013\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 8.8818e-04 - val_loss: 0.0014\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9.0446e-04 - val_loss: 0.0014\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.9207e-04 - val_loss: 0.0013\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 8.9868e-04 - val_loss: 0.0014\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.9376e-04 - val_loss: 0.0013\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 8.8114e-04 - val_loss: 0.0013\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.9510e-04 - val_loss: 0.0013\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 8.8077e-04 - val_loss: 0.0014\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 8.8539e-04 - val_loss: 0.0014\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 8.9421e-04 - val_loss: 0.0013\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 8.8436e-04 - val_loss: 0.0014\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 8.7958e-04 - val_loss: 0.0014\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 8.7650e-04 - val_loss: 0.0013\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.9346e-04 - val_loss: 0.0014\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 8.7018e-04 - val_loss: 0.0014\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 8.6808e-04 - val_loss: 0.0014\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 9.1159e-04 - val_loss: 0.0014\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 8.6504e-04 - val_loss: 0.0013\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.7693e-04 - val_loss: 0.0013\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 8.7709e-04 - val_loss: 0.0014\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 9.0787e-04 - val_loss: 0.0013\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 8.6230e-04 - val_loss: 0.0014\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 8.6241e-04 - val_loss: 0.0014\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 8.6193e-04 - val_loss: 0.0013\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 8.6319e-04 - val_loss: 0.0013\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.7014e-04 - val_loss: 0.0013\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.5590e-04 - val_loss: 0.0013\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.5748e-04 - val_loss: 0.0013\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 8.5290e-04 - val_loss: 0.0014\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 8.5587e-04 - val_loss: 0.0013\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.6136e-04 - val_loss: 0.0013\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 8.5271e-04 - val_loss: 0.0013\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 8.5407e-04 - val_loss: 0.0013\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 8.4882e-04 - val_loss: 0.0013\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.5045e-04 - val_loss: 0.0013\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 8.4523e-04 - val_loss: 0.0013\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.4551e-04 - val_loss: 0.0013\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 8.4632e-04 - val_loss: 0.0013\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.5652e-04 - val_loss: 0.0013\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 8.5452e-04 - val_loss: 0.0013\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.4313e-04 - val_loss: 0.0013\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 8.4635e-04 - val_loss: 0.0013\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 8.3779e-04 - val_loss: 0.0013\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 8.5019e-04 - val_loss: 0.0013\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.3449e-04 - val_loss: 0.0013\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 8.3902e-04 - val_loss: 0.0013\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 8.4580e-04 - val_loss: 0.0013\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 8.3203e-04 - val_loss: 0.0013\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 8.3065e-04 - val_loss: 0.0013\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 8.3110e-04 - val_loss: 0.0013\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 8.4675e-04 - val_loss: 0.0013\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 8.2877e-04 - val_loss: 0.0013\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 8.4118e-04 - val_loss: 0.0013\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 8.2816e-04 - val_loss: 0.0013\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.2838e-04 - val_loss: 0.0013\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.4810e-04 - val_loss: 0.0013\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.2474e-04 - val_loss: 0.0013\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.4993e-04 - val_loss: 0.0013\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 8.2160e-04 - val_loss: 0.0013\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 8.1804e-04 - val_loss: 0.0013\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 8.2091e-04 - val_loss: 0.0013\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.2247e-04 - val_loss: 0.0013\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 8.1713e-04 - val_loss: 0.0013\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 8.1517e-04 - val_loss: 0.0013\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 8.1328e-04 - val_loss: 0.0013\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 8.1558e-04 - val_loss: 0.0013\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.1770e-04 - val_loss: 0.0013\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 8.1452e-04 - val_loss: 0.0013\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 8.2665e-04 - val_loss: 0.0013\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 8.3643e-04 - val_loss: 0.0013\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 8.0700e-04 - val_loss: 0.0013\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.3440e-04 - val_loss: 0.0013\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 8.4110e-04 - val_loss: 0.0014\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 8.1163e-04 - val_loss: 0.0013\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 8.3433e-04 - val_loss: 0.0013\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 8.0300e-04 - val_loss: 0.0014\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 8.3194e-04 - val_loss: 0.0013\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 8.1570e-04 - val_loss: 0.0013\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 8.1534e-04 - val_loss: 0.0013\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.2327e-04 - val_loss: 0.0013\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.9695e-04 - val_loss: 0.0013\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 8.0318e-04 - val_loss: 0.0013\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 7.9403e-04 - val_loss: 0.0013\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 7.9764e-04 - val_loss: 0.0013\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.0002e-04 - val_loss: 0.0013\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 7.9467e-04 - val_loss: 0.0013\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 8.0611e-04 - val_loss: 0.0013\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.9683e-04 - val_loss: 0.0013\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 7.9345e-04 - val_loss: 0.0013\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 8.0358e-04 - val_loss: 0.0013\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 7.8988e-04 - val_loss: 0.0013\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 7.9270e-04 - val_loss: 0.0013\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 7.9015e-04 - val_loss: 0.0013\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.8809e-04 - val_loss: 0.0013\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.8922e-04 - val_loss: 0.0013\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 7.8975e-04 - val_loss: 0.0012\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.8469e-04 - val_loss: 0.0013\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 8.0584e-04 - val_loss: 0.0013\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 7.9210e-04 - val_loss: 0.0013\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 7.9085e-04 - val_loss: 0.0013\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.0492e-04 - val_loss: 0.0012\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 7.8084e-04 - val_loss: 0.0013\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.0267e-04 - val_loss: 0.0013\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 7.9201e-04 - val_loss: 0.0013\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.0192e-04 - val_loss: 0.0013\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.8788e-04 - val_loss: 0.0012\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 7.8382e-04 - val_loss: 0.0012\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 7.7517e-04 - val_loss: 0.0013\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 7.7947e-04 - val_loss: 0.0012\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.6780e-04 - val_loss: 0.0012\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.6338e-04 - val_loss: 0.0013\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.6442e-04 - val_loss: 0.0013\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 7.5628e-04 - val_loss: 0.0012\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 7.5905e-04 - val_loss: 0.0012\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 7.5710e-04 - val_loss: 0.0013\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.5726e-04 - val_loss: 0.0012\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 7.5097e-04 - val_loss: 0.0012\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.5604e-04 - val_loss: 0.0012\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 7.5922e-04 - val_loss: 0.0012\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.4953e-04 - val_loss: 0.0012\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.5176e-04 - val_loss: 0.0013\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.5560e-04 - val_loss: 0.0013\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 7.4218e-04 - val_loss: 0.0012\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 7.5252e-04 - val_loss: 0.0012\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.4553e-04 - val_loss: 0.0013\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 7.4835e-04 - val_loss: 0.0012\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 7.5203e-04 - val_loss: 0.0013\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.4557e-04 - val_loss: 0.0013\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 7.6340e-04 - val_loss: 0.0012\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.7069e-04 - val_loss: 0.0013\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 7.3874e-04 - val_loss: 0.0012\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 7.3803e-04 - val_loss: 0.0012\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 7.3266e-04 - val_loss: 0.0012\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.3131e-04 - val_loss: 0.0012\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 7.2829e-04 - val_loss: 0.0012\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.4420e-04 - val_loss: 0.0012\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.2629e-04 - val_loss: 0.0012\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 7.3604e-04 - val_loss: 0.0012\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.6301e-04 - val_loss: 0.0012\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.1908e-04 - val_loss: 0.0012\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.4510e-04 - val_loss: 0.0012\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.4074e-04 - val_loss: 0.0012\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 7.5084e-04 - val_loss: 0.0012\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 7.2901e-04 - val_loss: 0.0012\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 7.3150e-04 - val_loss: 0.0012\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 7.2703e-04 - val_loss: 0.0012\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 7.3058e-04 - val_loss: 0.0013\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 7.3284e-04 - val_loss: 0.0012\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 7.2367e-04 - val_loss: 0.0012\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 7.2587e-04 - val_loss: 0.0012\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 7.2630e-04 - val_loss: 0.0012\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 7.1734e-04 - val_loss: 0.0012\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 7.3199e-04 - val_loss: 0.0012\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.3324e-04 - val_loss: 0.0012\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.2016e-04 - val_loss: 0.0012\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 7.2465e-04 - val_loss: 0.0012\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.1982e-04 - val_loss: 0.0012\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 7.1970e-04 - val_loss: 0.0012\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 7.4809e-04 - val_loss: 0.0012\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 7.0415e-04 - val_loss: 0.0013\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.2466e-04 - val_loss: 0.0012\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 7.0525e-04 - val_loss: 0.0012\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.1072e-04 - val_loss: 0.0012\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 7.2220e-04 - val_loss: 0.0012\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 7.0996e-04 - val_loss: 0.0012\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 7.1769e-04 - val_loss: 0.0012\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 7.0536e-04 - val_loss: 0.0012\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 7.0547e-04 - val_loss: 0.0012\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 7.1024e-04 - val_loss: 0.0012\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 6.9864e-04 - val_loss: 0.0012\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 7.0680e-04 - val_loss: 0.0012\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 7.3073e-04 - val_loss: 0.0012\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 7.0164e-04 - val_loss: 0.0012\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 7.0259e-04 - val_loss: 0.0012\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 7.0274e-04 - val_loss: 0.0012\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 6.9953e-04 - val_loss: 0.0012\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 7.0802e-04 - val_loss: 0.0012\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 7.0443e-04 - val_loss: 0.0012\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 6.9868e-04 - val_loss: 0.0012\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 7.0053e-04 - val_loss: 0.0012\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 6.9720e-04 - val_loss: 0.0012\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 6.8986e-04 - val_loss: 0.0012\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 7.0221e-04 - val_loss: 0.0012\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 7.0141e-04 - val_loss: 0.0011\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 6.9877e-04 - val_loss: 0.0012\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 7.1270e-04 - val_loss: 0.0012\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 6.8235e-04 - val_loss: 0.0012\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 7.0063e-04 - val_loss: 0.0012\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 7.1012e-04 - val_loss: 0.0012\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 6.9685e-04 - val_loss: 0.0012\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 6.8847e-04 - val_loss: 0.0012\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.8694e-04 - val_loss: 0.0012\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 6.8095e-04 - val_loss: 0.0012\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 6.8403e-04 - val_loss: 0.0012\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 6.8353e-04 - val_loss: 0.0012\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 6.7946e-04 - val_loss: 0.0012\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.7694e-04 - val_loss: 0.0012\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 6.8623e-04 - val_loss: 0.0012\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 6.8118e-04 - val_loss: 0.0012\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 6.8433e-04 - val_loss: 0.0012\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.8749e-04 - val_loss: 0.0012\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 6.7793e-04 - val_loss: 0.0012\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.0899e-04 - val_loss: 0.0012\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 6.8231e-04 - val_loss: 0.0012\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.7161e-04 - val_loss: 0.0012\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 6.7922e-04 - val_loss: 0.0012\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 6.8008e-04 - val_loss: 0.0012\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 6.8805e-04 - val_loss: 0.0012\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 6.6894e-04 - val_loss: 0.0012\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 6.7310e-04 - val_loss: 0.0012\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 6.7739e-04 - val_loss: 0.0012\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.6983e-04 - val_loss: 0.0012\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 6.8562e-04 - val_loss: 0.0012\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.6575e-04 - val_loss: 0.0012\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 7.1211e-04 - val_loss: 0.0012\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 6.8802e-04 - val_loss: 0.0013\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 6.7405e-04 - val_loss: 0.0012\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 6.9458e-04 - val_loss: 0.0012\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 6.8677e-04 - val_loss: 0.0012\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 6.6208e-04 - val_loss: 0.0012\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 6.8688e-04 - val_loss: 0.0012\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.7136e-04 - val_loss: 0.0012\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 6.8822e-04 - val_loss: 0.0012\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.7699e-04 - val_loss: 0.0012\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 7.2802e-04 - val_loss: 0.0012\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 7.0965e-04 - val_loss: 0.0012\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 6.9595e-04 - val_loss: 0.0012\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.7898e-04 - val_loss: 0.0011\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.6507e-04 - val_loss: 0.0012\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 6.6110e-04 - val_loss: 0.0012\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 6.6850e-04 - val_loss: 0.0012\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.6134e-04 - val_loss: 0.0012\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.6328e-04 - val_loss: 0.0012\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.6132e-04 - val_loss: 0.0012\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.5049e-04 - val_loss: 0.0012\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 6.5759e-04 - val_loss: 0.0012\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.5179e-04 - val_loss: 0.0012\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 6.5801e-04 - val_loss: 0.0012\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.6306e-04 - val_loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "# Running Regression Model\n",
    "history = ANN_model.fit(X_train_scaled, y_train_scaled, validation_data=(X_test_scaled, y_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting Test Values\n",
    "y_pred_scaled = history.model_.predict(X_test_scaled) \n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986632620152653 0.9986632635005089\n",
      "0.0012329944202830157 0.3305869133551952\n"
     ]
    }
   ],
   "source": [
    "# Generating Metrics (scaled and unscaled)\n",
    "r2 = r2_score(y_test_scaled, y_pred_scaled)\n",
    "mse = mean_squared_error(y_test_scaled, y_pred_scaled)\n",
    "r2_unscaled = r2_score(y_test, y_pred)\n",
    "mse_unscaled = mean_squared_error(y_test,y_pred)\n",
    "print(r2, r2_unscaled)  # These are the same\n",
    "print(mse, mse_unscaled)  # These are not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dasm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
